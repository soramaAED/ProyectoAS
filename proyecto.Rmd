---
title: "Proyecto"
output: html_document
date: "2024-12-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#################
### LIBRERIAS ###
#################

library(jpeg)
library(class)
library(caret)
library(imager)
library(magick)
library(e1071)    # Para SVR y SVM
library(xgboost)  # Para XGBoost
library(dplyr)    # Para manipulación de datos
library(randomForest) # Para Random Forest
library(mlbench)  # Para selección de características
library(Rtsne)    # Para visualización t-SNE
library(ggplot2)
library(plotly)

# Establecer la semilla para reproducibilidad
set.seed(42)
```

# Carga de datos
```{r}
if (file.exists("./particiones_datos.RData")) {
  
  # Cargar el archivo .RData
  load("./particiones_datos.RData")
  cat("Partición de datos cargada correctamente.\n")
  
} else {
  
  # Ruta base a las imagenes
  path <- "./data"
  
  ###
  ### Conversion .webp a .jpg
  ###
  
  # Obtener todas las carpetas (etiquetas)
  carpetas_etiquetas <- list.dirs(path, recursive = FALSE, full.names = TRUE)
  
  # Verificar si hay al menos un archivo .webp en las carpetas
  hay_webp <- any(sapply(carpetas_etiquetas, function(carpeta) {
    length(list.files(carpeta, pattern = "\\.webp$", full.names = TRUE)) > 0
  }))
  
  if (hay_webp) {
    # Obtener todas las carpetas (etiquetas)
    carpetas_etiquetas <- list.dirs(path, recursive = FALSE, full.names = TRUE)
    
    # Función para reemplazar imágenes .webp con su conversión a .jpg
    convertir_webp_a_jpg <- function(carpeta) {
      # Listar las imagenes .webp en la carpeta
      imagenes_webp <- list.files(carpeta, pattern = "\\.webp$", full.names = TRUE)
      
      for (ruta_webp in imagenes_webp) {
        # Cargar la imagen
        img <- image_read(ruta_webp)
        
        # Crear el nuevo nombre de archivo con extensión .jpg
        ruta_jpg <- sub("\\.webp$", ".jpg", ruta_webp)  # Cambiar la extensión
        
        # Guardar la imagen convertida como .jpg
        image_write(img, path = ruta_jpg, format = "jpg")
        
        # Eliminar el archivo original .webp
        file.remove(ruta_webp)
      }
    }
    
    # Procesar todas las carpetas de etiquetas
    for (carpeta in carpetas_etiquetas) {
      convertir_webp_a_jpg(carpeta)
    }
    
    cat("Todas las imágenes .webp han sido convertidas a .jpg.\n")
  }
  
  ###
  ### Generacion metadatos
  ###
  
  source("generacionMetadatos.R")
  
  ### 
  ### Importacion datos
  ###
  
  # Ruta a las imagenes y carga de metadatos
  files <- dir(path, full.names = TRUE, recursive = TRUE)
  csvfile <- "./dataset_metadata.csv"
  meta <- read.csv(csvfile, as.is = TRUE)
  
  
  ###
  ### Particionado de los datos
  ###
  
  # Crear índices de muestreo estratificado
  train_indices <- createDataPartition(meta$etiqueta, p = 0.7, list = FALSE)
  
  # Dividir en entrenamiento y prueba
  files_train <- files[train_indices]
  files_test <- files[-train_indices]
  
  meta_train <- meta[train_indices, ]
  meta_test <- meta[-train_indices, ]
  
  # Verificar proporciones de "soleado", "nublado" y "noche" en los conjuntos
  prop_train <- table(meta_train$etiqueta) / nrow(meta_train)
  prop_test <- table(meta_test$etiqueta) / nrow(meta_test)
  
  cat("\nProporciones en entrenamiento:")
  print(prop_train)
  
  cat("\nProporciones en prueba:")
  print(prop_test)
  
  # Crear etiquetas (tags) para el conjunto de entrenamiento
  ### 
  ### NOCHE   -> 0
  ### SOLEADO -> 1
  ### NUBLADO -> 2
  ### 
  pchSymb_train <- rep(0, length(files_train))
  pchSymb_train[meta_train$etiqueta == "soleado"] <- 1
  pchSymb_train[meta_train$etiqueta == "nublado"] <- 2
  
  # Crear etiquetas (tags) para el conjunto de prueba
  ### 
  ### NOCHE   -> 0
  ### SOLEADO -> 1
  ### NUBLADO -> 2
  ### 
  pchSymb_test <- rep(0, length(files_test))
  pchSymb_test[meta_test$etiqueta == "soleado"] <- 1
  pchSymb_test[meta_test$etiqueta == "nublado"] <- 2
   
  save(files_train, files_test, pchSymb_train, pchSymb_test, file = "particiones_datos.RData")
  cat("\nLas particiones han sido guardadas correctamente en el archivo 'particiones_datos.RData'.\n")
}
```

# Preparación de los datos
```{r}
# Dimensiones deseadas para el reescalado
new_width <- 640
new_height <- 640

# Función para reescalar una sola imagen
reescalar_imagen <- function(ruta_imagen, new_width, new_height) {
  if (file.exists(ruta_imagen)) {  # Verifica si la imagen existe
    img <- load.image(ruta_imagen)
    img_resized <- resize(img, new_width, new_height)
    return(img_resized)
  } else {
    warning(paste("El archivo", ruta_imagen, "no existe."))
    return(NULL)
  }
}

# Función para procesar un conjunto de imagenes (lista de rutas)
reescalar_particion <- function(particion, new_width, new_height) {
  # Aplicar reescalado a todas las imagenes
  imagenes_reescaladas <- lapply(particion, reescalar_imagen, new_width = new_width, new_height = new_height)
  
  # Filtrar imagenes que no se pudieron cargar
  imagenes_reescaladas <- imagenes_reescaladas[!sapply(imagenes_reescaladas, is.null)]
  
  return(imagenes_reescaladas)
}

# Reescalar imagenes de train y test
imagenes_train <- reescalar_particion(files_train, new_width, new_height)
imagenes_test <- reescalar_particion(files_test, new_width, new_height)

# Verifica los resultados
length(imagenes_train)  # Número de imágenes reescaladas en train
length(imagenes_test)   # Número de imágenes reescaladas en test

# Mostrar la primera imagen reescalada
plot(imagenes_train[[1]])

```

```{r}
###########
### RGB ###
###########

# Crea una matriz para almacenar los valores medianos de R, G y B para el conjunto de train
# Usamos las imagenes reescaladas!!!
RGB_train <- matrix(0, nrow = length(imagenes_train), ncol = 3)

# Itera sobre las imágenes
for (j in 1:length(imagenes_train)) {
  # Obtén la imagen directamente del vector
  z <- imagenes_train[[j]]
  # Calcula la mediana de cada canal de color
  RGB_train[j, 1] = median(z[,,1]) #R
  RGB_train[j, 2] = median(z[,,2]) #G
  RGB_train[j, 3] = median(z[,,3]) #B
}

# Crea una matriz para almacenar los valores medianos de R, G y B para el conjunto de test
# Usamos las imagenes reescaladas!!!
RGB_test <- matrix(0, nrow = length(imagenes_test), ncol = 3)

# Itera sobre las imágenes
for (j in 1:length(imagenes_test)) {
  # Obtén la imagen directamente del vector
  z <- imagenes_test[[j]]
  # Calcula la mediana de cada canal de color
  RGB_test[j, 1] = median(z[,,1]) #R
  RGB_test[j, 2] = median(z[,,2]) #G
  RGB_test[j, 3] = median(z[,,3]) #B
}

```

Además de la mediana, podemos extraer características estadísticas avanzadas de las imágenes, como Skewness, Kurtosis y contraste promedio, para capturar patrones únicos en la distribución de los valores de color o brillo. Estas métricas son útiles porque nos dan información sobre la variabilidad, la forma y la dispersión de los datos, complementando otras características como las medianas de los canales RGB o HSV.

La Skewness (Asimetría) mide si los datos están distribuidos simétricamente o tienen un sesgo hacia un lado:
•	Si el valor es cero, la distribución es simétrica.
•	Si es positivo, los valores tienden a acumularse en el lado izquierdo (cola derecha larga).
•	Si es negativo, los valores se acumulan en el lado derecho (cola izquierda larga).
En el procesamiento de imágenes un sesgo positivo o negativo en los canales RGB puede indicar colores predominantes o niveles de brillo desbalanceados, como cielos brillantes o áreas oscuras.

La Kurtosis es una medida de la forma de la distribución de las intensidades de píxeles en las imágenes digitales. Un alto valor de Kurtosis (>3) indica que los datos tienen un pico más alto colas más pesadas que una distribución normal (Puede representar imágenes con áreas uniformes y pocos bordes), mientras que un valor de Kurtosis bajo (<3) indica que la distribución es más plana y tiene colas más ligeras que una distribución normal (Puede representar imágenes con variabilidad uniforme, como cielos nublados).

El contraste promedio mide la diferencia media de intensidad entre píxeles adyacentes en una imagen. Es útil para evaluar la "nitidez" de los patrones, donde un contraste alto indica bordes marcados y transiciones abruptas, típico en imágenes soleadas con sombras fuertes y un contraste bajo indica transiciones suaves, típico en imágenes nubladas o nocturnas.

La idea es hacer un análisis combinado usando todas estas métricas juntas como un vector de características (ejemplo: [skew_R, skew_G, skew_B, kurtosis_R, kurtosis_G, kurtosis_B, contraste])

```{r}
library(e1071)  # Para skewness y kurtosis

calcular_estadisticas <- function(imagenes_train) {
  # Crear una matriz para las características
  estadisticas <- matrix(0, nrow = length(imagenes_train), ncol = 13)
  colnames(estadisticas) <- c("skew_R", "skew_G", "skew_B", 
                               "kurtosis_R", "kurtosis_G", "kurtosis_B", "brillo_medio",
                               "contraste", "porc_claros", "porc_oscuros", "gris", "oscuro", "claro")
  
  for (j in 1:length(imagenes_train)) {
    img <- imagenes_train[[j]]
    
    # Separación canales
    R <- as.numeric(img[,,1])
    G <- as.numeric(img[,,2])
    B <- as.numeric(img[,,3])
    
    # skewness y kurtosis
    estadisticas[j, 1] <- skewness(R)
    estadisticas[j, 2] <- skewness(G)
    estadisticas[j, 3] <- skewness(B)
    estadisticas[j, 4] <- kurtosis(R)
    estadisticas[j, 5] <- kurtosis(G)
    estadisticas[j, 6] <- kurtosis(B)
    
    # Contraste (desviación estándar del brillo promedio)
    brillo <- rowMeans(img, dims = 2) # Calcula el brillo promedio de cada fila de píxeles en la imagen, a lo largo de los canales (dims = 2)
    estadisticas[j, 7] <- mean(brillo)
    estadisticas[j, 8] <- sd(brillo)
    estadisticas[j, 9] <- (sum(brillo > 0.7) / length(brillo)) * 100
    estadisticas[j, 10] <- (sum(brillo < 0.3) / length(brillo)) * 100
    
    # 1. Gris (nublado): R, G y B casi iguales
    gris <- abs(R - G) < 0.1 & abs(G - B) < 0.1 & abs(R - B) < 0.1

    # 2. Negro azulado (noche): Baja intensidad en R y G, pero alta en B
    negro_azulado <- R < 0.2 & G < 0.2 & B > 0.4

    # 3. Azul claro (soleado): Alta intensidad en B, con R y G moderados
    azul_claro <- R > 0.4 & G > 0.4 & B > 0.6

    # Calcular el porcentaje de píxeles en cada color
    estadisticas[j, 11] <- sum(gris) / length(gris) * 100
    estadisticas[j, 12] <- sum(negro_azulado) / length(negro_azulado) * 100
    estadisticas[j, 13] <- sum(azul_claro) / length(azul_claro) * 100

  }
  
  return(estadisticas)
}

# Usar la función con el vector de imágenes
car_estadisticas_train <- calcular_estadisticas(imagenes_train)
car_estadisticas_test <- calcular_estadisticas(imagenes_test)
print(car_estadisticas_train)
```

Hue, Saturation, Value, HSV, (Tono Saturación Valor) es un modelo de color alternativo al RGB. El Tono (H) son los tres colores primarios y los tres secundarios de la rueda cromática. La Saturación (S) es la pureza e intensidad del color; cuanto más baja sea, más se acercará el color al gris. El Valor (V) se refiere a la claridad u oscuridad relativa de un color. Cada uno de estos valores tiene un límite; H va de 0-360, S y V van de 0-100.

```{r}
###########
### HSV ###
###########

# Matrices para almacenar los valores HSV para los conjuntos de entrenamiento y prueba
HSV_train <- matrix(0, nrow = nrow(RGB_train), ncol = 3)
HSV_test <- matrix(0, nrow = nrow(RGB_test), ncol = 3)

for (i in 1:nrow(RGB_train)) {
  HSV_train[i, ] <- rgb2hsv( RGB_train[i, 1], RGB_train[i, 2], RGB_train[i, 3])
  HSV_train[i,1] <- atan2(mean(sin(HSV_train[i, 1] * 2 * pi)), mean(cos(HSV_train[i, 1] * 2 * pi))) / (2 * pi) # es el arctg del angulo del que le doy sin y cos, entre 0 y 1, estoy desaciendo la circularidad, dando más peso a la H
}

for (i in 1:nrow(RGB_test)) {
  HSV_test[i, ] <- rgb2hsv(RGB_test[i, 1], RGB_test[i, 2], RGB_test[i, 3])
  HSV_test[i,1] <- atan2(mean(sin(HSV_test[i, 1] * 2 * pi)), mean(cos(HSV_test[i, 1] * 2 * pi))) / (2 * pi) 
}
```



IDEA: Las imágenes de día o soleadas pueden tener más variación de alta frecuencia debido a sombras y detalles, mientras que las de noche o nublado pueden tener más componentes de baja frecuencia.

```{r}
#########################################
# Características basadas en frecuencia #
#########################################

# Función para calcular características de frecuencia de imágenes
extraer_caracteristicas_fft <- function(imagenes_train) {
  # Crea una matriz para almacenar las características
  caracteristicas_fft <- matrix(0, nrow = length(imagenes_train), ncol = 2)
  colnames(caracteristicas_fft) <- c("Baja_Frecuencia", "Alta_Frecuencia")
  
  # Iteramos sobre cada imagen en el vector
  for (j in 1:length(imagenes_train)) {
    # Carga la imagen
    img <- imagenes_train[[j]]
    
    # Conversión a escala de grises si tiene 3 canales (RGB)
    # La FFT se aplica a una sola banda de datos.
    if (dim(img)[3] == 3) {
      img <- grayscale(as.cimg(img))
    }
    
    # Transformada de Fourier
    fft_img <- fft(as.numeric(img))
    
    # Espectro de frecuencias (magnitud del FFT)
    mag_fft <- Mod(fft_img)
    
    # Reestructuramos como una matriz 2D para análisis
    mag_fft_matrix <- matrix(mag_fft, nrow = dim(img)[1], ncol = dim(img)[2])
    
    # Partición en frecuencias bajas y altas
    # Las frecuencias bajas están concentradas en el centro del espectro
    centro <- floor(dim(mag_fft_matrix) / 2)
    # Se define un radio basado en el tamaño de la imagen para enmascarar las frecuencias bajas.
    radio <- min(centro) / 4 
    
    # Crea una máscara para frecuencias bajas
    mask <- matrix(0, nrow = dim(mag_fft_matrix)[1], ncol = dim(mag_fft_matrix)[2])
    for (x in 1:dim(mask)[1]) {
      for (y in 1:dim(mask)[2]) {
        dist <- sqrt((x - centro[1])^2 + (y - centro[2])^2)
        if (dist <= radio) {
          mask[x, y] <- 1
        }
      }
    }
    
    # Calculo de energía de frecuencias bajas y altas
    baja_freq <- sum(mag_fft_matrix * mask)
    alta_freq <- sum(mag_fft_matrix * (1 - mask))
    
    # Se guardan las características en la matriz
    # Tendremos dos columnas: energía de frecuencias bajas y altas para cada imagen.
    caracteristicas_fft[j, 1] <- baja_freq
    caracteristicas_fft[j, 2] <- alta_freq
  }
  
  return(caracteristicas_fft)
}

# Empleo de la función
car_frecuencia_train <- extraer_caracteristicas_fft(imagenes_train)
car_frecuencia_test <- extraer_caracteristicas_fft(imagenes_test)

# Mostrar las características extraídas
print(car_frecuencia_train)
print(car_frecuencia_test)
```
En imágenes, la frecuencia describe cómo cambian los valores de los píxeles (intensidades o colores) a lo largo de la imagen.De hecho, frecuencias bajas representan cambios lentos y suaves, como áreas de color uniforme o gradientes suaves, como el brillo general o la uniformidad (útil para detectar nublado y noche).De la misma manera, frecuencias altas representan cambios rápidos, como bordes, texturas, detalles finos o ruido (útil para imagenes de día y soleado).
Aplicando la Transformada de Fourier a la imagen, analizamos cómo cambian las intensidades en términos de frecuencias y lo que obtenemos es una matriz con las frecuencias bajas en el centro y las frecuencias altas hacia las esquinas.Para poder separar las frecuencias, usamos una máscara circular de valor 1 en el área definida por el radio y 0 fuera de ella, para frecuencias bajas y el complemento de dicha máscara para frecuencias altas bajas. Ahora que tenemos la división hecha, lo único que falta es el cálculo de la energía, que lo obtenemos simplemente sumando el valor absoluto (magnitud) de las componentes de frecuencia dentro de cada región (baja y alta). Esto nos da una medida de cuánta información está contenida en cada rango de frecuencias.



## Transformada Wavelet 

La Transformada Wavelet es una herramienta que descompone una imagen en componentes de frecuencia de diferentes resoluciones. Esto es útil para capturar detalles a diferentes escalas en la imagen.

```{r}
#########################################
# Características basadas en Wavelet #
#########################################

library(waveslim)
library(wavelets)

# Modificar el código para obtener las sub-bandas como columnas
extraer_caracteristicas_wavelet_detalladas <- function(imagenes_train) {
  # Crea una matriz para almacenar las características (ahora con 4 columnas)
  caracteristicas_wavelet <- matrix(0, nrow = length(imagenes_train), ncol = 4)
  colnames(caracteristicas_wavelet) <- c("LL_Baja_Frecuencia", "LH_Alta_Frecuencia", "HL_Alta_Frecuencia", "HH_Alta_Frecuencia")
  
  # Iteramos sobre cada imagen
  for (j in 1:length(imagenes_train)) {
    # Carga la imagen
    img <- imagenes_train[[j]]
    
    # Conversión a escala de grises si tiene 3 canales (RGB)
    if (dim(img)[3] == 3) {
      img <- grayscale(as.cimg(img))
    }
    
    # Convertimos la imagen a una matriz numérica
    img_matrix <- as.numeric(img)
    img_matrix <- matrix(img_matrix, nrow = dim(img)[1], ncol = dim(img)[2])
    
    # Transformada Wavelet 2D
    wavelet_img <- dwt(img_matrix, filter = "haar", n.levels = 3)
    
    # Extraer sub-bandas
    LL <- wavelet_img$LL
    LH <- wavelet_img$LH
    HL <- wavelet_img$HL
    HH <- wavelet_img$HH
    
    # Cálculo de la energía de cada sub-banda
    LL_energy <- sum(LL^2)
    LH_energy <- sum(LH^2)
    HL_energy <- sum(HL^2)
    HH_energy <- sum(HH^2)
    
    # Guardar las características
    caracteristicas_wavelet[j, 1] <- LL_energy
    caracteristicas_wavelet[j, 2] <- LH_energy
    caracteristicas_wavelet[j, 3] <- HL_energy
    caracteristicas_wavelet[j, 4] <- HH_energy
  }
  
  return(caracteristicas_wavelet)
}

# Empleo de la nueva función
car_wavelet_train_detalladas <- extraer_caracteristicas_wavelet_detalladas(imagenes_train)
car_wavelet_test_detalladas <- extraer_caracteristicas_wavelet_detalladas(imagenes_test)

# Mostrar las características extraídas
print(car_wavelet_train_detalladas)
print(car_wavelet_test_detalladas)

```


## Enetrenamiento de modelos

```{r}
#########################################
# Entrenamiento de modelos #
#########################################
# Juntar las matrices de entrenamiento y prueba

car_estadisticas_train <- as.data.frame(car_estadisticas_train)
car_frecuencia_train <- as.data.frame(car_frecuencia_train)
hsv_train <- as.data.frame(HSV_train)
rgb_train <- as.data.frame(RGB_train)

car_estadisticas_test <- as.data.frame(car_estadisticas_test)
car_frecuencia_test <- as.data.frame(car_frecuencia_test)
hsv_test <- as.data.frame(HSV_test)
rgb_test <- as.data.frame(RGB_test)

# Concatenar todas las features para el conjunto de entrenamiento y prueba
X_train <- cbind(car_estadisticas_train, car_frecuencia_train, hsv_train, rgb_train)
X_test <- cbind(car_estadisticas_test, car_frecuencia_test, hsv_test, rgb_test)

# Convertir las etiquetas a formato factor
meta_train$etiqueta <- as.factor(meta_train$etiqueta)
meta_test$etiqueta <- as.factor(meta_test$etiqueta)

y_train <- meta_train$etiqueta
y_test <- meta_test$etiqueta

# Visualización inicial con t-SNE en 3D
tsne_result <- Rtsne(as.matrix(X_train), dims = 3, perplexity = 30, verbose = TRUE, max_iter = 500)
tsne_data <- as.data.frame(tsne_result$Y)
tsne_data$Etiqueta <- y_train

# Crear el gráfico 3D usando plotly
fig <- plot_ly(tsne_data, x = ~V1, y = ~V2, z = ~V3, color = ~Etiqueta, colors = RColorBrewer::brewer.pal(9, "Set1"),
               marker = list(size = 5, opacity = 0.7, line = list(width = 0.5, color = 'black'))) %>%
  layout(title = "Visualización de t-SNE en 3D",
         scene = list(xaxis = list(title = "Dimensión 1"),
                      yaxis = list(title = "Dimensión 2"),
                      zaxis = list(title = "Dimensión 3")))

# Mostrar el gráfico
fig

# Visualización con PCA en 3D
pca_result <- prcomp(scale(as.matrix(X_train)), center = TRUE, scale. = TRUE)
pca_data <- pca_result$x
pca_df <- data.frame(PC1 = pca_data[, 1], PC2 = pca_data[, 2], PC3 = pca_data[,3])
pca_df$Etiqueta <- y_train

# Crear el gráfico 3D usando plotly
fig2 <- plot_ly(pca_df, x = ~pca_df[,1], y = ~pca_df[,2], z = ~pca_df[,3], color = ~Etiqueta, colors = RColorBrewer::brewer.pal(9, "Set1"),
               marker = list(size = 5, opacity = 0.7, line = list(width = 0.5, color = 'black'))) %>%
  layout(title = "Visualización de PCA en 3D",
         scene = list(xaxis = list(title = "Dimensión 1"),
                      yaxis = list(title = "Dimensión 2"),
                      zaxis = list(title = "Dimensión 3")))

fig2


# Entrenar y evaluar modelos

# Definir una función para calcular métricas de evaluación
evaluar_modelo <- function(predicciones, reales) {
  confusion <- confusionMatrix(as.factor(predicciones), as.factor(reales))
  print(confusion)
  
  precision <- confusion$byClass["Pos Pred Value"]
  recall <- confusion$byClass["Sensitivity"]

  return(list(
    Accuracy = confusion$overall["Accuracy"],
    Kappa = confusion$overall["Kappa"],
    Precision = precision,
    Recall = recall
    ))
}


# Modelo 1: SVR (Support Vector Classifier)
modelo_svr <- svm(X_train, y = y_train, type = "C-classification", kernel = "radial", cost = 1, gamma = 0.1)
predicciones_svr <- predict(modelo_svr, X_test)
cat("\nEvaluación del modelo SVR:\n")
metricas_svr <- evaluar_modelo(predicciones_svr, y_test)

# Modelo 2: XGBoost
# Convertir los datos a formato de matriz para XGBoost
X_train_matrix <- as.matrix(X_train)
X_test_matrix <- as.matrix(X_test)
dtrain <- xgb.DMatrix(data = X_train_matrix, label = as.numeric(y_train) - 1)
dtest <- xgb.DMatrix(data = X_test_matrix, label = as.numeric(y_test) - 1)

param <- list(objective = "multi:softmax", num_class = length(levels(y_train)))
modelo_xgb <- xgboost(params = param, data = dtrain, nrounds = 100, verbose = 0)
predicciones_xgb <- predict(modelo_xgb, dtest)
predicciones_xgb <- factor(predicciones_xgb, levels = 0:(length(levels(y_train)) - 1), labels = levels(y_train))
cat("\nEvaluación del modelo XGBoost:\n")
metricas_xgb <- evaluar_modelo(predicciones_xgb, y_test)

# Modelo 3: KNN
# Elegir el valor de k (puedes ajustar este valor para mejorar el rendimiento)
k <- 7
predicciones_knn <- knn(train = X_train, test = X_test, cl = y_train, k = k)
cat("\nEvaluación del modelo KNN:\n")
metricas_knn <- evaluar_modelo(predicciones_knn, y_test)

# Modelo 4: Random Forest
modelo_rf <- randomForest(x = X_train, y = y_train, ntree = 100, mtry = sqrt(ncol(X_train)), importance = TRUE)
predicciones_rf <- predict(modelo_rf, X_test)
cat("\nEvaluación del modelo Random Forest:\n")
metricas_rf <- evaluar_modelo(predicciones_rf, y_test)

# Modelo 5: Naive Bayes
modelo_nb <- naiveBayes(X_train, y_train)
predicciones_nb <- predict(modelo_nb, X_test)
cat("\nEvaluación del modelo Naive Bayes:\n")
metricas_nb <- evaluar_modelo(predicciones_nb, y_test)

# Resumen de resultados
resultados <- data.frame(
  Modelo = c("SVR", "XGBoost", "KNN", "Random Forest", "Naive Bayes"),
  Accuracy = c(metricas_svr$Accuracy, metricas_xgb$Accuracy, metricas_knn$Accuracy, metricas_rf$Accuracy, metricas_nb$Accuracy),
  Kappa = c(metricas_svr$Kappa, metricas_xgb$Kappa, metricas_knn$Kappa, metricas_rf$Kappa, metricas_nb$Kappa)
)

print("\nResumen de resultados:")
print(resultados)

```

